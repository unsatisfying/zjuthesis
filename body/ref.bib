% use `texdoc biblatex` to get help
@www{zjuthesisrules,
    title = {浙江大学本科生毕业论文（设计）编写规则},
    author = {浙江大学本科生院},
    year = {2018},
    url = {http://bksy.zju.edu.cn/attachments/2018-01/01-1517384518-1149149.pdf},
}
@www{tikz,
    title = {tikz宏包},
    author = {Till Tantau},
    year = {2018},
    url = {https://sourceforge.net/projects/pgf/},
}
@www{zjuthesis,
    title = {浙江大学毕业设计/论文模板},
    author = {王子轩},
    year = {2019},
    url = {https://github.com/TheNetAdmin/zjuthesis},
}
@www{zjugradthesisrules,
    title = {浙江大学研究生学位论文编写规则},
    author = {浙江大学研究生院},
    year = {2008},
    url = {http://grs.zju.edu.cn/redir.php?catalog_id=10038&object_id=12877},
}

@www{BYD2023L3,
  author = {{比亚迪}},
  title = {比亚迪获全国首张 {L3} 自动驾驶高快速路测试牌照，全面加速智能化布局},
  url = {https://www.byd.com/cn/news/2023/detail496},
  note = {发布于 2023‑12‑27，首次获得 L3 级自动驾驶测试牌照时间为 2023‑07‑21，地点：深圳市，中国},
  year = {2023},
  langid = {chinese}
}

@www{AppleSiri2025,
  author = {{Apple Inc.}},
  title = {Siri},
  url = {https://www.apple.com/siri/},
  note = {访问日期: 2025‑07‑30, 官方页面介绍 Siri 可用语音控制设备多项操作，并强调隐私安全},
  year = {2025},
  langid = {english}
}

@www{HuaweiXiaoyi2025,
  author = {{Huawei}},
  title = {小艺助手},
  url = {https://xiaoyi.huawei.com/chat/},
  year = {2025}
}

@www{OpenAIChatGPT2022,
  author = {{OpenAI}},
  title = {ChatGPT},
  url = {https://openai.com/zh-Hans-CN/index/chatgpt/},
  year = {2022}
}

@www{opencv-python,
  author = {Bradski, Gary and the OpenCV team},
  title = {opencv-python: OpenCV library for Python},
  year = {2025},
  url = {https://pypi.org/project/opencv-python/}
}

@www{huggingface2024,
  author       = {Hugging Face Inc.},
  title        = {{Hugging Face Hub}: A Platform for Sharing Machine Learning Models, Datasets and Demos},
  howpublished = {\url{https://huggingface.co/}},
  year         = {2026},
  note         = {Accessed: 2024-11-15}
}

@www{modelzoo2024,
  title        = {{Model Zoo}: A Collection of Pre-trained Deep Learning Models},
  author       = {{Various Contributors}},
  howpublished = {\url{https://modelzoo.co/}},
  year         = {2026},
  note         = {Community-maintained platform for model sharing. Accessed: 2024-11-15}
}

@www{tensorflowhub2024,
  title        = {{TensorFlow Hub}: A Repository of Trained Machine Learning Models},
  author       = {{Google Research}},
  howpublished = {\url{https://www.tensorflow.org/hub}},
  year         = {2026},
  note         = {Library for reusable machine learning modules}
}

@inproceedings{cheng2022conflict,
author = {Cheng, Wei and Zhu, Xiangrong and Hu, Wei},
title = {Conflict-Aware Inference of Python Compatible Runtime Environments with Domain Knowledge Graph},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510078},
doi = {10.1145/3510003.3510078},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {451–461},
numpages = {11},
keywords = {configuration management, knowledge graph, python, conflict resolution, dependency solving, runtime environment inference},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{mukherjee2021fixing,
  title={Fixing dependency errors for Python build reproducibility},
  author={Mukherjee, Suchita and Almanza, Abigail and Rubio-Gonz{\'a}lez, Cindy},
  booktitle={Proceedings of the 30th ACM SIGSOFT international symposium on software testing and analysis},
  pages={439--451},
  year={2021}
}

@misc{pipreq,
  title =  {pipreq},
  author = {Jessamyn Smith},
  url = {https://github.com/bndr/pipreqs/},
  year = {2023},
}

@inproceedings{ye2022knowledge,
  title={Knowledge-based environment dependency inference for Python programs},
  author={Ye, Hongjie and Chen, Wei and Dou, Wensheng and Wu, Guoquan and Wei, Jun},
  booktitle={Proceedings of the 44th International Conference on Software Engineering},
  pages={1245--1256},
  year={2022}
}

@article{mahon2025pypitfall,
  title={PyPitfall: Dependency Chaos and Software Supply Chain Vulnerabilities in Python},
  author={Mahon, Jacob and Hou, Chenxi and Yao, Zhihao},
  journal={arXiv preprint arXiv:2507.18075},
  year={2025}
}

@article{alfadel2023empirical,
author = {Alfadel, Mahmoud and Costa, Diego Elias and Shihab, Emad},
title = {Empirical analysis of security vulnerabilities in Python packages},
year = {2023},
issue_date = {May 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-022-10278-4},
doi = {10.1007/s10664-022-10278-4},
abstract = {Software ecosystems play an important role in modern software development, providing an open platform of reusable packages that speed up and facilitate development tasks. However, this level of code reusability supported by software ecosystems also makes the discovery of security vulnerabilities much more difficult, as software systems depend on an increasingly high number of packages. Recently, security vulnerabilities in the npm ecosystem, the ecosystem of Node.js packages, have been studied in the literature. As different software ecosystems embody different programming languages and particularities, we argue that it is also important to study other popular programming languages to build stronger empirical evidence about vulnerabilities in software ecosystems. In this paper, we present an empirical study of 1,396 vulnerability reports affecting 698 Python packages in the Python ecosystem (PyPi). In particular, we study the propagation and life span of security vulnerabilities, accounting for how long they take to be discovered and fixed. In addition, vulnerabilities in packages may affect software projects that depend on them (dependent projects), making them vulnerable too. We study a set of 2,224 GitHub Python projects, to better understand the prevalence of vulnerabilities in their dependencies and how fast it takes to update them. Our findings show that the discovered vulnerabilities in Python packages are increasing over time, and they take more than 3 years to be discovered. A large portion of these vulnerabilities (40.86\%) are only fixed after being publicly announced, giving ample time for attackers exploitation. Moreover, we find that more than half of the dependent projects rely on at least one vulnerable package, taking a considerably long time (7 months) to update to a non-vulnerable version. We find similarities in some characteristics of vulnerabilities in PyPi and npm and divergences that can be attributed to specific PyPi policies. By leveraging our findings, we provide a series of implications that can help the security of software ecosystems by improving the process of discovering, fixing and managing package vulnerabilities.},
journal = {Empirical Softw. Engg.},
month = mar,
numpages = {37},
keywords = {Empirical studies, Vulnerabilities, Packages, PyPi, Python}
}

@ARTICLE{bogaerts2024taxonomy,
  author={Bogaerts, Frédéric C. G. and Ivaki, Naghmeh and Fonseca, José},
  journal={IEEE Open Journal of the Computer Society}, 
  title={A Taxonomy for Python Vulnerabilities}, 
  year={2024},
  volume={5},
  number={},
  pages={368-379},
  keywords={Python;Security;Taxonomy;Codes;Artificial intelligence;Training;Testing;Computing milieux;error handling and recovery;management of computing and information systems;reliability;software engineering;software/software engineering;software quality/SQA;security and protection;testing and debugging},
  doi={10.1109/OJCS.2024.3422686}}

@article{cao2023towards,
author = {Cao, Yulu and Chen, Lin and Ma, Wanwangying and Li, Yanhui and Zhou, Yuming and Wang, Linzhang},
title = {Towards Better Dependency Management: A First Look at Dependency Smells in Python Projects},
year = {2023},
issue_date = {April 2023},
publisher = {IEEE Press},
volume = {49},
number = {4},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2022.3191353},
doi = {10.1109/TSE.2022.3191353},
abstract = {Managing cross-project dependencies is tricky in modern software development. A primary way to manage dependencies is using dependency configuration files, which brings convenience to the entire software ecosystem, including developers, maintainers, and users. However, developers may introduce dependency smells if dependency configuration files are not well written and maintained. Dependency smells are recurring violations of dependency management in dependency configuration files and can potentially lead to severe consequences. This paper provides an in-depth look at three dependency smells, namely, <italic>Missing Dependency</italic>, <italic>Bloated Dependency</italic>, and <italic>Version Constraint Inconsistency</italic> in Python projects. First, we implement a tool called <underline>Py</underline>thon <underline>C</underline>ross-project <underline>D</underline>ependency- PyCD to accurately extract dependency information from configuration files. The evaluation result on 212 Python projects shows that PyCD outperforms state-of-the-art tools. Then, we make an empirical study for three dependency smells in 132 Python projects to investigate the pervasiveness, causes, and evolution. The results show that: 1) dependency smells are prevalent in Python projects and exist inconsistently in different projects; 2) dependency smells are introduced into Python projects for different reasons, mainly due to the problems of synchronous update and collaborative development; and 3) dependency smells can be removed with different patterns according to different dependency smells. Furthermore, we report and get responses for 40 harmful dependency smell instances, 34 of which have been responded that these dependency smells do exist in the projects, and 10 instances are fixed or under process. The feedback from developers indicates that dependency smells can have a negative impact on project maintenance. Our study highlights that these dependency smells deserve the attention of developers.},
journal = {IEEE Trans. Softw. Eng.},
month = apr,
pages = {1741–1765},
numpages = {25}
}

@inproceedings{abadi2016tensorflow,
  title={$\{$TensorFlow$\}$: a system for $\{$Large-Scale$\}$ machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th USENIX symposium on operating systems design and implementation (OSDI 16)},
  pages={265--283},
  year={2016}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@INPROCEEDINGS{ladisa2023taxonomy,
  author={Ladisa, Piergiorgio and Plate, Henrik and Martinez, Matias and Barais, Olivier},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={SoK: Taxonomy of Attacks on Open-Source Software Supply Chains}, 
  year={2023},
  volume={},
  number={},
  pages={1509-1526},
  keywords={Surveys;Visualization;Costs;Taxonomy;Supply chains;Malware;Security;Open Source;Security;Software Supply Chain;Malware;Attack},
  doi={10.1109/SP46215.2023.10179304}}

@article{sonatype2021,
  author = {Sonatype},
  title = {State of the 2021 Software Supply Chain},
  year = {2021},
  journal = {Sonatype Blog},
  url = {https://www.sonatype.com/blog/software-supply-chain-2021},
}

@inproceedings{akhoundali2024morefixes,
  title={MoreFixes: A large-scale dataset of CVE fix commits mined through enhanced repository discovery},
  author={Akhoundali, Jafar and Nouri, Sajad Rahim and Rietveld, Kristian and Gadyatskaya, Olga},
  booktitle={Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
  pages={42--51},
  year={2024}
}

@www{huggingface-2m-models,
    author = {Francisco Ríos},
    title = {Hugging Face's two million models and counting},
    year = {2025},
    month = dec,
    day = {8},
    url = {https://aiworld.eu/stories/hugging-face-two-million-models},
    note = {Accessed: 2025-12-24},
    publisher = {AI World}
}

@www{jfrog-malicious-huggingface-models,
    author = {{JFrog Security Research Team}},
    title = {Examining Malicious Hugging Face ML Models with Silent Backdoor},
    year = {2025},
    url = {https://research.jfrog.com/examining-malicious-hugging-face-ml-models-with-silent-backdoor/},
    note = {Accessed: 2025-12-24},
    publisher = {JFrog Security Research}
}

@INPROCEEDINGS{ji2017backdoor,
  author={Ji, Yujie and Zhang, Xinyang and Wang, Ting},
  booktitle={2017 IEEE Conference on Communications and Network Security (CNS)}, 
  title={Backdoor attacks against learning systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  keywords={Feature extraction;Security;Data mining;Skin cancer;Force;Tuning;Conferences},
  doi={10.1109/CNS.2017.8228656}}

  @article{kurakin2016adversarial,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}

@article{gu2019badnets,
  title={Badnets: Evaluating backdooring attacks on deep neural networks},
  author={Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={Ieee Access},
  volume={7},
  pages={47230--47244},
  year={2019},
  publisher={IEEE}
}

@article{turner2019label,
  title={Label-consistent backdoor attacks},
  author={Turner, Alexander and Tsipras, Dimitris and Madry, Aleksander},
  journal={arXiv preprint arXiv:1912.02771},
  year={2019}
}

@article{huang2017adversarial,
  title={Adversarial attacks on neural network policies},
  author={Huang, Sandy and Papernot, Nicolas and Goodfellow, Ian and Duan, Yan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1702.02284},
  year={2017}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@article{yin2024lobam,
  title={LoBAM: LoRA-Based Backdoor Attack on Model Merging},
  author={Yin, Ming and Zhang, Jingyang and Sun, Jingwei and Fang, Minghong and Li, Hai and Chen, Yiran},
  journal={arXiv preprint arXiv:2411.16746},
  year={2024}
}

@article{liu2024lora,
  title={Lora-as-an-attack! piercing llm safety under the share-and-play scenario},
  author={Liu, Hongyi and Liu, Zirui and Tang, Ruixiang and Yuan, Jiayi and Zhong, Shaochen and Chuang, Yu-Neng and Li, Li and Chen, Rui and Hu, Xia},
  journal={arXiv e-prints},
  pages={arXiv--2403},
  year={2024}
}


@article{hua2024malmodel,
title={MalModel: Hiding Malicious Payload in Mobile Deep Learning Models with Black-box Backdoor Attack},
author={Hua, Jiayi and Wang, Kailong and Wang, Meizhen and Bai, Guangdong and Luo, Xiapu and Wang, Haoyu},
journal={arXiv preprint arXiv:2401.02659},
year={2024}
}

@article{hitaj2024trust,
title={Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem},
author={Hitaj, Dorjan and Pagnotta, Giulio and De Gaspari, Fabio and Ruko, Sediola and Hitaj, Briland and Mancini, Luigi V. and Perez-Cruz, Fernando},
journal={arXiv preprint arXiv:2403.03593},
year={2024}
}

@inproceedings{10.1145/3427228.3427268,
author = {Liu, Tao and Liu, Zihao and Liu, Qi and Wen, Wujie and Xu, Wenyao and Li, Ming},
title = {StegoNet: Turn Deep Neural Network into a Stegomalware},
year = {2020},
isbn = {9781450388580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427228.3427268},
doi = {10.1145/3427228.3427268},
abstract = {Deep Neural Networks (DNNs) are now presenting human-level performance on many real-world applications, and DNN-based intelligent services are becoming more and more popular across all aspects of our lives. Unfortunately, the ever-increasing DNN service implies a dangerous feature which has not yet been well studied–allowing the marriage of existing malware and DNN model for any pre-defined malicious purpose. In this paper, we comprehensively investigate how to turn DNN into a new breed evasive self-contained stegomalware, namely StegoNet, using model parameter as a novel payload injection channel, with no service quality degradation (i.e. accuracy) and the triggering event connected to the physical world by specified DNN inputs. A series of payload injection techniques which take advantage of a variety of unique neural network natures like complex structure, high error resilience capability and huge parameter size, are developed for both uncompressed models (with model redundancy) and deeply compressed models tailored for resource-limited devices (no model redundancy), including LSB substitution, resilience training, value mapping, and sign-mapping. We also proposed a set of triggering techniques like logits trigger, rank trigger and fine-tuned rank trigger to trigger StegoNet by specific physical events under realistic environment variations. We implement the StegoNet prototype on Nvidia Jetson TX2 testbed. Extensive experimental results and discussions on the evasiveness, integrity of proposed payload injection techniques, and the reliability and sensitivity of the triggering techniques, well demonstrate the feasibility and practicality of StegoNet.},
booktitle = {Proceedings of the 36th Annual Computer Security Applications Conference},
pages = {928–938},
numpages = {11},
location = {<conf-loc>, <city>Austin</city>, <country>USA</country>, </conf-loc>},
series = {ACSAC '20}
}
@article{wang2022evilmodel,
  title={Evilmodel 2.0: bringing neural network models into malware attacks},
  author={Wang, Zhi and Liu, Chaoge and Cui, Xiang and Yin, Jie and Wang, Xutong},
  journal={Computers \& Security},
  volume={120},
  pages={102807},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{wang2021evilmodel,
  title={Evilmodel: hiding malware inside of neural network models},
  author={Wang, Zhi and Liu, Chaoge and Cui, Xiang},
  booktitle={2021 IEEE Symposium on Computers and Communications (ISCC)},
  pages={1--7},
  year={2021},
  organization={IEEE}
}

@www{tensorflow-rce-poc,
    author = {Splinter0},
    title = {Tensorflow Remote Code Execution with Malicious Model},
    year = {2024},
    url = {https://github.com/Splinter0/tensorflow-rce},
    note = {Accessed: 2025-12-26},
    publisher = {GitHub}
}

@www{cert-vul-253266,
    author = {{CERT Coordination Center}},
    title = {Vulnerability Note VU\#253266},
    year = {2025},
    url = {https://kb.cert.org/vuls/id/253266},
    note = {Accessed: 2025-12-26},
    publisher = {CERT/CC}
}

@www{hackernews-sleepy-pickle,
    author = {{The Hacker News}},
    title = {New Attack Technique 'Sleepy Pickle' Targets Machine Learning Models},
    year = {2024},
    month = jun,
    url = {https://thehackernews.com/2024/06/new-attack-technique-sleepy-pickle.html},
    note = {Accessed: 2025-12-26},
    publisher = {The Hacker News}
}

@www{github-pickle-attacks,
    author = {pjcampbe11},
    title = {Pickle-File-Attacks},
    year = {2024},
    url = {https://github.com/pjcampbe11/Pickle-File-Attacks},
    note = {Accessed: 2025-12-26},
    publisher = {GitHub}
}

@www{trailofbits-pickle-attacks,
    author = {{Trail of Bits}},
    title = {Exploiting ML Models with Pickle File Attacks (Part 1)},
    year = {2024},
    month = jun,
    day = {11},
    url = {https://blog.trailofbits.com/2024/06/11/exploiting-ml-models-with-pickle-file-attacks-part-1/},
    note = {Accessed: 2025-12-26},
    publisher = {Trail of Bits}
}